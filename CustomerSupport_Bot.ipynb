{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b146d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rough\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "LANGCHAIN_API_KEY = 'ls__01321d45ed594748ba1d3043c5e85106'\n",
    "os.environ['LANGCHAIN_API_KEY'] = LANGCHAIN_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b59cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "gemini_api_key=\"AIzaSyD-99BgMe4YOiumsWnogkx_QPQN1-9Sqv8\"\n",
    "os.environ['GOOGLE_API_KEY'] = gemini_api_key\n",
    "\n",
    "GROQ_API_KEY=\"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\"\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
    "\n",
    "\n",
    "cohere_api_key=\"rhPt2ghX1NaFQlYmPYS7S3hfVRqpsFRPTFo5rYZf\"\n",
    "os.environ['cohere_api_key'] = cohere_api_key\n",
    "\n",
    "\n",
    "voyage_api=\"pa-l5w3vl8YVQWbDn958fD6q1JiUvfJ7clnK2KWmroBuKw\"\n",
    "os.environ[\"VOYAGE_API_KEY\"]=voyage_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cdb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool\n",
    "def monthly_payment(name: str) -> int:\n",
    "    \"\"\"\n",
    "        This tool will help to give new monthly payment for user\n",
    "        :param name: Full name of the customer\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(\"Loan_amount.csv\")\n",
    "        df.set_index('Name', inplace=True)\n",
    "        interest_rate = 0.05  #\n",
    "        monthly_payment = df.loc[name]['Monthly_Payment']\n",
    "        new_monthly_payment = monthly_payment * (1 + interest_rate) - monthly_payment\n",
    "        df.reset_index(inplace=True)\n",
    "        return new_monthly_payment\n",
    "    except Exception as e:\n",
    "        raise ToolException(\"The search tool1 is not available.\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44310d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 3\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to search the user's emails or calendar for more information.\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8b6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToLoanAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle loan adjustment\"\"\"\n",
    "\n",
    "    name: str = Field(\n",
    "        description=\"I need to use the tool to calculate the loan amount.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5344028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are loan agent called as Sandy from ABC bank  \"\n",
    "            \"Your primary role is to here to disscuss the loan payment this customer has a. \"\n",
    "            \"Use the given tool to calculate the new loan for his term, \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "        \n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\n{user_info}\\n\"\n",
    "            ,\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "     [\n",
    "        ToLoanAssistant,\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114e26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_tool=[monthly_payment]\n",
    "loan_tool_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are assitant capable of calculating loan . \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help calculating loans . \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" Remember that a calculation isn't completed until after the relevant tool has successfully been used.\"\n",
    "            '\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'Done Calculation !\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ])\n",
    "    \n",
    "loantool_runnable = loan_tool_prompt | llm.bind_tools(\n",
    "    loan_tool + [CompleteOrEscalate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824a2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"update_flight\",\n",
    "                \n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b42749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43586ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool.\"\n",
    "                    \" If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "\n",
    "    return entry_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad3f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(f\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c1ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea50020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    }
   ],
   "source": [
    "builder.set_entry_point(\"primary_loan_assitant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd4cf0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_tools=[monthly_payment]\n",
    "builder.add_node(\n",
    "    \"enter_loan_calculator\",\n",
    "    create_entry_node(\"Loan_calculator\", \"update_loan_calculator\"),\n",
    ")\n",
    "builder.add_node(\"update_loan_calculator_runnable\", Assistant(loantool_runnable))\n",
    "builder.add_edge(\"enter_loan_calculator\", \"update_loan_calculator_runnable\")\n",
    "builder.add_node(\n",
    "    \"update_loan_calc_tools\",\n",
    "    create_tool_node_with_fallback(loan_tools),\n",
    ")\n",
    "def route_update_flight(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"update_loan_calc_tools\",\n",
    "    \"leave_skill\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    return \"update_loan_calc_tools\"\n",
    "builder.add_edge(\"update_loan_calc_tools\", \"update_loan_calculator_runnable\")\n",
    "builder.add_conditional_edges(\"update_loan_calculator_runnable\", route_update_flight)\n",
    "\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_loan_assitant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "327c0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"primary_loan_assitant\", Assistant(assistant_runnable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73475bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_primary_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"enter_loan_calculator\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToLoanAssistant.__name__:\n",
    "            return \"enter_loan_calculator\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_loan_assitant\",\n",
    "    route_primary_assistant,\n",
    "    {\n",
    "        \"enter_loan_calculator\": \"enter_loan_calculator\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d5baeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory)\n",
    "    # Let the user approve or deny the use of sensitive tools\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbaf01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={\"messages\":\"hi what is my loan amount\"}\n",
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0f5474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'primary_loan_assitant':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'enter_loan_calculator':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'update_loan_calculator_runnable':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'leave_skill':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'primary_loan_assitant':\"\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for output in app.stream(a):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b707c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
